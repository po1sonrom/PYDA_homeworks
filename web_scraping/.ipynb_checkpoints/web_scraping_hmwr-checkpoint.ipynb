{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата> - <заголовок> - <ссылка>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Решение***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['python', 'парсинг']\n",
    "\n",
    "post_time = []\n",
    "title = []\n",
    "article_url = []\n",
    "url_list= []\n",
    "\n",
    "for url in BeautifulSoup(requests.get('https://habr.com/ru/all/').text, 'html.parser').find\\\n",
    "('div', class_='content_left js-content_left').find_all('a', class_='post__title_link'):\n",
    "    url_list.append(url.get('href'))\n",
    "\n",
    "for i in url_list: \n",
    "    soup = BeautifulSoup(requests.get(i).text, 'html.parser') \n",
    "\n",
    "    for keyword in keywords: \n",
    "        x = soup.find('div', class_='post__text post__text-html post__text_v1').get_text()\n",
    "\n",
    "        if keyword in x.lower(): \n",
    "            post_time.append(soup.find('span', class_='post__time').get_text()) \n",
    "            title.append(soup.find('span', class_='post__title-text').get_text()) \n",
    "            article_url.append(url_list)\n",
    "\n",
    "articles_data = pd.DataFrame({'Дата': post_time,'Заголовок': title,'Ссылка': article_url})\n",
    "articles_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. \n",
    "\n",
    "Список email-ов задаем переменной в начале кода:\n",
    "\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Решение***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = ['xxx@x.ru', 'yyy@y.com']\n",
    "url_ = 'https://digibody.avast.com/v1/web/leaks'\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in range(len(email)):\n",
    "    check = json.loads(requests.post(url_, data=json.dumps(email)).text)\n",
    "    \n",
    "    for x in range(len(check['value'])):\n",
    "        data = pd.concat([data, pd.DataFrame([{'почта': email[i],\\\n",
    "           'дата утечки': check['value'][x]['leak_info']['date'],\\\n",
    "           'источник утечки': check['value'][x]['leak_info']['title'],\\\n",
    "           'описание утечки': check['value'][x]['leak_info']['description']}])])\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
